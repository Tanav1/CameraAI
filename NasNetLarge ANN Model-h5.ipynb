{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f1d3eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.applications import NASNetLarge\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import pickle\n",
    "import tensorflow.keras as keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8be42252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Import\n",
    "#train_df = tf.keras.utils.image_dataset_from_directory(\"archive/train\",seed=45,image_size=(32, 32),batch_size=64)\n",
    "#test_df = tf.keras.utils.image_dataset_from_directory(\"archive/test\",seed=123,image_size=(32, 32),batch_size=64)\n",
    "\n",
    "# directories\n",
    "train_img_path = 'archive/train'\n",
    "test_img_path = 'archive/test'\n",
    "\n",
    "w,h = 32,32\n",
    "batch_size = 32\n",
    "\n",
    "train_data_gen = ImageDataGenerator(\n",
    "    rescale = 1.0/255\n",
    ")\n",
    "test_data_gen = ImageDataGenerator(rescale = 1.0/255)\n",
    "\n",
    "train_Dataset = train_data_gen.flow_from_directory(\n",
    "    train_img_path,\n",
    "    target_size = (w,h),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'binary',\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "test_Dataset = test_data_gen.flow_from_directory(\n",
    "    test_img_path,\n",
    "    target_size = (w,h),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'binary',\n",
    "    shuffle = False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed201c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_1 (Rescaling)     (None, 32, 32, 3)         0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 15, 15, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                460864    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 464,931\n",
      "Trainable params: 464,931\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = tf.keras.applications.NASNetLarge(\n",
    "#     input_shape=None,\n",
    "#     include_top=False,\n",
    "#     weights=\"imagenet\",\n",
    "#     input_tensor=None,\n",
    "#     pooling=None,\n",
    "#     classes=1000,\n",
    "#     classifier_activation=\"softmax\",\n",
    "# )\n",
    "\n",
    "\n",
    "#model = keras.applications.NASNetMobile(weights=None, input_shape=(32, 32, 3), classes=7)\n",
    "layers = []\n",
    "layers.append(tf.keras.layers.Rescaling(1./255)) # Normalise pixel values\n",
    "layers.append(tf.keras.layers.Conv2D(32, 3, activation='relu'))\n",
    "layers.append(tf.keras.layers.MaxPooling2D())\n",
    "layers.append(tf.keras.layers.Flatten())\n",
    "\n",
    "# Building the ANN\n",
    "layers.append(tf.keras.layers.Dense(64, activation='relu'))\n",
    "layers.append(tf.keras.layers.Dense(32, activation='relu'))\n",
    "layers.append(tf.keras.layers.Dense(32, activation='softmax'))\n",
    "\n",
    "\n",
    "layers.append(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "layers.append(tf.keras.layers.Dense(1, activation='softmax'))\n",
    "\n",
    "\n",
    "# Create and compile the model from layers\n",
    "model = tf.keras.Sequential(layers)\n",
    "model.compile(\n",
    "  optimizer='Adamax',\n",
    "  loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "# Build the model so we can see a summary\n",
    "model.build(input_shape=(None, 32, 32, 3))\n",
    "model.summary()\n",
    "\n",
    "# model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 15, 15, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 6, 6, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 2, 2, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 224833 (878.25 KB)\n",
      "Trainable params: 224833 (878.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the model\n",
    "model2 = models.Sequential()\n",
    "\n",
    "# Convolutional layers\n",
    "#model2.add(layers.Rescaling(1./255))\n",
    "model2.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "model2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "model2.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten layer\n",
    "model2.add(layers.Flatten())\n",
    "\n",
    "# Dense layers\n",
    "model2.add(layers.Dense(256, activation='relu'))\n",
    "model2.add(layers.Dropout(0.5))  # Optional dropout for regularization\n",
    "model2.add(layers.Dense(1, activation='sigmoid'))  # Output layer with 1 neuron (binary classification)\n",
    "\n",
    "# Compile the model\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print a summary of the model architecture\n",
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3125/3125 [==============================] - 38s 12ms/step - loss: 1.0671 - accuracy: 0.8266 - precision_8: 0.8252 - recall_8: 0.8287 - val_loss: 3.3679 - val_accuracy: 0.7873 - val_precision_8: 0.7668 - val_recall_8: 0.8258\n",
      "Epoch 2/10\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 35.4486 - accuracy: 0.7233 - precision_8: 0.7254 - recall_8: 0.7185 - val_loss: 91.3068 - val_accuracy: 0.7061 - val_precision_8: 0.6741 - val_recall_8: 0.7982\n",
      "Epoch 3/10\n",
      "3125/3125 [==============================] - 36s 12ms/step - loss: 300.7697 - accuracy: 0.6876 - precision_8: 0.6889 - recall_8: 0.6843 - val_loss: 639.9877 - val_accuracy: 0.6671 - val_precision_8: 0.6918 - val_recall_8: 0.6028\n",
      "Epoch 4/10\n",
      "3125/3125 [==============================] - 36s 12ms/step - loss: 1034.3495 - accuracy: 0.6706 - precision_8: 0.6719 - recall_8: 0.6667 - val_loss: 1600.6239 - val_accuracy: 0.6496 - val_precision_8: 0.8548 - val_recall_8: 0.3603\n",
      "Epoch 5/10\n",
      "3125/3125 [==============================] - 36s 11ms/step - loss: 2490.8350 - accuracy: 0.6499 - precision_8: 0.6516 - recall_8: 0.6440 - val_loss: 2988.9539 - val_accuracy: 0.6621 - val_precision_8: 0.6798 - val_recall_8: 0.6127\n",
      "Epoch 6/10\n",
      "3125/3125 [==============================] - 35s 11ms/step - loss: 4525.4014 - accuracy: 0.6335 - precision_8: 0.6351 - recall_8: 0.6276 - val_loss: 10044.7539 - val_accuracy: 0.6195 - val_precision_8: 0.6651 - val_recall_8: 0.4816\n",
      "Epoch 7/10\n",
      "3125/3125 [==============================] - 36s 12ms/step - loss: 7517.1294 - accuracy: 0.6179 - precision_8: 0.6196 - recall_8: 0.6111 - val_loss: 16483.5645 - val_accuracy: 0.6170 - val_precision_8: 0.7547 - val_recall_8: 0.3467\n",
      "Epoch 8/10\n",
      "3125/3125 [==============================] - 36s 11ms/step - loss: 12491.6465 - accuracy: 0.6045 - precision_8: 0.6058 - recall_8: 0.5986 - val_loss: 28496.5977 - val_accuracy: 0.5965 - val_precision_8: 0.6375 - val_recall_8: 0.4474\n",
      "Epoch 9/10\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 17684.2969 - accuracy: 0.5979 - precision_8: 0.5991 - recall_8: 0.5917 - val_loss: 23816.0977 - val_accuracy: 0.6138 - val_precision_8: 0.6772 - val_recall_8: 0.4351\n",
      "Epoch 10/10\n",
      "3125/3125 [==============================] - 39s 13ms/step - loss: 26150.8398 - accuracy: 0.5856 - precision_8: 0.5867 - recall_8: 0.5795 - val_loss: 96866.0000 - val_accuracy: 0.5815 - val_precision_8: 0.6070 - val_recall_8: 0.4625\n"
     ]
    }
   ],
   "source": [
    "model2.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "history = model2.fit(\n",
    "  train_Dataset,\n",
    "  validation_data=test_Dataset,\n",
    "  epochs=10,\n",
    "  verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794370e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-11 10:27:49.088738: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [100000]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-11-11 10:27:49.089041: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [100000]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-11-11 10:27:49.783804: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-11-11 10:27:49.862417: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4681 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-11 10:28:21.180368: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [20000]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-11-11 10:28:21.180605: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [20000]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-11-11 10:28:21.264501: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 38s 21ms/step - loss: 0.4681 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 1.0000 - val_loss: 0.3537 - val_accuracy: 0.5000 - val_precision_1: 0.5000 - val_recall_1: 1.0000\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.3303 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 1.0000 - val_loss: 0.3022 - val_accuracy: 0.5000 - val_precision_1: 0.5000 - val_recall_1: 1.0000\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.3182 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 1.0000 - val_loss: 0.3467 - val_accuracy: 0.5000 - val_precision_1: 0.5000 - val_recall_1: 1.0000\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.3392 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 1.0000 - val_loss: 0.3400 - val_accuracy: 0.5000 - val_precision_1: 0.5000 - val_recall_1: 1.0000\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.3607 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 1.0000 - val_loss: 0.3404 - val_accuracy: 0.5000 - val_precision_1: 0.5000 - val_recall_1: 1.0000\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.3901 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 1.0000 - val_loss: 0.3808 - val_accuracy: 0.5000 - val_precision_1: 0.5000 - val_recall_1: 1.0000\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.3914 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 1.0000 - val_loss: 0.3535 - val_accuracy: 0.5000 - val_precision_1: 0.5000 - val_recall_1: 1.0000\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.3895 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 1.0000 - val_loss: 0.4494 - val_accuracy: 0.5000 - val_precision_1: 0.5000 - val_recall_1: 1.0000\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.3926 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 1.0000 - val_loss: 0.3755 - val_accuracy: 0.5000 - val_precision_1: 0.5000 - val_recall_1: 1.0000\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 26s 16ms/step - loss: 0.4570 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 1.0000 - val_loss: 0.4355 - val_accuracy: 0.5000 - val_precision_1: 0.5000 - val_recall_1: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(\n",
    "  train_Dataset,\n",
    "  validation_data=test_Dataset,\n",
    "  epochs=10,\n",
    "  verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b5a0ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('m2.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22e4b69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_input = input(\"Enter your input: \")\n",
    "user_input1 = \"archive/train/REAL/0000 (5).jpg\"\n",
    "user_input = '/Users/brian/Desktop/IMG_6017.jpg'\n",
    "#\"sample_data/train_fake-1477_4.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a251226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "{'FAKE': 0, 'REAL': 1}\n",
      "Model predictions: [[1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Preprocess the user input (assuming user_input is the input image file path)\n",
    "img = image.load_img(user_input1, target_size=(32, 32))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "#img_array /= 255.0  # Normalize pixel values\n",
    "\n",
    "# Get model predictions\n",
    "predictions = model2.predict(img_array)\n",
    "predicted_class = np.argmax(predictions)\n",
    "\n",
    "binary_predictions = (predictions > 0.5).astype(int)\n",
    "binary_predictions\n",
    "\n",
    "print(train_Dataset.class_indices)\n",
    "\n",
    "print(\"Model predictions:\", binary_predictions)\n",
    "#print(predicted_class)\n",
    "\n",
    "# if predicted_class == 0:\n",
    "#     predicted_label = \"real\"\n",
    "# else:\n",
    "#     predicted_label = \"fake\"\n",
    "# a\n",
    "#     print(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/brian/Desktop/Camera AI/NasNetLarge ANN Model-h5.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/brian/Desktop/Camera%20AI/NasNetLarge%20ANN%20Model-h5.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m predictions \u001b[39m=\u001b[39m model2\u001b[39m.\u001b[39;49mpredict(\u001b[39m'\u001b[39;49m\u001b[39marchive/test/FAKE/0 (4).jpg\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brian/Desktop/Camera%20AI/NasNetLarge%20ANN%20Model-h5.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m predictions\n",
      "File \u001b[0;32m/opt/miniconda3/envs/hackathon/lib/python3.11/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/miniconda3/envs/hackathon/lib/python3.11/site-packages/tensorflow/python/framework/tensor_shape.py:957\u001b[0m, in \u001b[0;36mTensorShape.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    956\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_v2_behavior:\n\u001b[0;32m--> 957\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dims[key]\n\u001b[1;32m    958\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    959\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdims[key]\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "predictions = model2.predict('archive/test/FAKE/0 (4).jpg')\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ffcaf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "Predicted class: real\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.99\n",
    "\n",
    "# Get model predictions\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Check if the prediction score is greater than or equal to the threshold\n",
    "if predictions >= threshold:\n",
    "    predicted_class = \"fake\"\n",
    "else:\n",
    "    predicted_class = \"real\"\n",
    "\n",
    "print(\"Predicted class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4671bf76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_predictions = (predictions > 0.5).astype(int)\n",
    "binary_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3afcc650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.build(input_shape=(None, 32, 32, 3))\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# history = model.fit(\n",
    "#   train_df,\n",
    "#   validation_data=test_df,\n",
    "#   epochs=5,\n",
    "#   verbose=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58df4b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0383c246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
