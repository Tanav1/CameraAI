{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f1d3eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-11 08:30:58.848345: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.applications import NASNetLarge\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import tensorflow.keras as keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8be42252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-11 08:31:11.793268: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-11 08:31:11.793356: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Import\n",
    "train_df = tf.keras.utils.image_dataset_from_directory(\"archive/train\",seed=45,image_size=(32, 32),batch_size=64)\n",
    "test_df = tf.keras.utils.image_dataset_from_directory(\"archive/test\",seed=123,image_size=(32, 32),batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed201c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 32, 32, 3)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 7200)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                460864    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 464,933\n",
      "Trainable params: 464,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = tf.keras.applications.NASNetLarge(\n",
    "#     input_shape=None,\n",
    "#     include_top=False,\n",
    "#     weights=\"imagenet\",\n",
    "#     input_tensor=None,\n",
    "#     pooling=None,\n",
    "#     classes=1000,\n",
    "#     classifier_activation=\"softmax\",\n",
    "# )\n",
    "\n",
    "\n",
    "#model = keras.applications.NASNetMobile(weights=None, input_shape=(32, 32, 3), classes=7)\n",
    "layers = []\n",
    "layers.append(tf.keras.layers.Rescaling(1./255)) # Normalise pixel values\n",
    "layers.append(tf.keras.layers.Conv2D(32, 3, activation='relu'))\n",
    "layers.append(tf.keras.layers.MaxPooling2D())\n",
    "layers.append(tf.keras.layers.Flatten())\n",
    "\n",
    "# Building the ANN\n",
    "layers.append(tf.keras.layers.Dense(64, activation='relu'))\n",
    "layers.append(tf.keras.layers.Dense(32, activation='relu'))\n",
    "layers.append(tf.keras.layers.Dense(32, activation='softmax'))\n",
    "\n",
    "\n",
    "layers.append(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "layers.append(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "# Create and compile the model from layers\n",
    "model = tf.keras.Sequential(layers)\n",
    "model.compile(\n",
    "  optimizer='Adamax',\n",
    "  loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "# Build the model so we can see a summary\n",
    "model.build(input_shape=(None, 32, 32, 3))\n",
    "model.summary()\n",
    "\n",
    "# model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4028ae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "794370e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-11 08:32:35.235021: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [100000]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-11-11 08:32:35.235350: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [100000]\n",
      "\t [[{{node Placeholder/_4}}]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/opt/miniconda3/envs/hackathon/lib/python3.11/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/miniconda3/envs/hackathon/lib/python3.11/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/miniconda3/envs/hackathon/lib/python3.11/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/miniconda3/envs/hackathon/lib/python3.11/site-packages/keras/engine/training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/opt/miniconda3/envs/hackathon/lib/python3.11/site-packages/keras/engine/training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"/opt/miniconda3/envs/hackathon/lib/python3.11/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/opt/miniconda3/envs/hackathon/lib/python3.11/site-packages/keras/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/opt/miniconda3/envs/hackathon/lib/python3.11/site-packages/keras/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/opt/miniconda3/envs/hackathon/lib/python3.11/site-packages/keras/losses.py\", line 2156, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/opt/miniconda3/envs/hackathon/lib/python3.11/site-packages/keras/backend.py\", line 5707, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 2) vs (None, 1)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/brian/Desktop/Camera AI/NasNetLarge ANN Model 1.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/brian/Desktop/Camera%20AI/NasNetLarge%20ANN%20Model%201.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brian/Desktop/Camera%20AI/NasNetLarge%20ANN%20Model%201.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m   train_df,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brian/Desktop/Camera%20AI/NasNetLarge%20ANN%20Model%201.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m   validation_data\u001b[39m=\u001b[39;49mtest_df,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brian/Desktop/Camera%20AI/NasNetLarge%20ANN%20Model%201.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m   epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brian/Desktop/Camera%20AI/NasNetLarge%20ANN%20Model%201.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m   verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brian/Desktop/Camera%20AI/NasNetLarge%20ANN%20Model%201.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/hackathon/lib/python3.11/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/lw/_7j3pqbs5qqdv74c5lx55gtr0000gn/T/__autograph_generated_fileciil_7nb.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/miniconda3/envs/hackathon/lib/python3.11/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/miniconda3/envs/hackathon/lib/python3.11/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/miniconda3/envs/hackathon/lib/python3.11/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/miniconda3/envs/hackathon/lib/python3.11/site-packages/keras/engine/training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/opt/miniconda3/envs/hackathon/lib/python3.11/site-packages/keras/engine/training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"/opt/miniconda3/envs/hackathon/lib/python3.11/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/opt/miniconda3/envs/hackathon/lib/python3.11/site-packages/keras/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/opt/miniconda3/envs/hackathon/lib/python3.11/site-packages/keras/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/opt/miniconda3/envs/hackathon/lib/python3.11/site-packages/keras/losses.py\", line 2156, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/opt/miniconda3/envs/hackathon/lib/python3.11/site-packages/keras/backend.py\", line 5707, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 2) vs (None, 1)).\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "  train_df,\n",
    "  validation_data=test_df,\n",
    "  epochs=10,\n",
    "  verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b5a0ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22e4b69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_input = input(\"Enter your input: \")\n",
    "user_input1 = \"archive/test/REAL/0079 (2).jpg\"\n",
    "user_input = 'archive/test/REAL/0318 (2).jpg'\n",
    "#\"sample_data/train_fake-1477_4.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a251226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "Model predictions: [[0.40270525 0.59729475]]\n",
      "0.59729475\n",
      "1\n",
      "fake\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Preprocess the user input (assuming user_input is the input image file path)\n",
    "img = image.load_img(user_input, target_size=(32, 32))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "img_array /= 255.0  # Normalize pixel values\n",
    "\n",
    "# Get model predictions\n",
    "predictions = model.predict(img_array)\n",
    "predicted_class = np.argmax(predictions)\n",
    "\n",
    "print(\"Model predictions:\", predictions)\n",
    "print(predictions[0][1])\n",
    "print(predicted_class)\n",
    "\n",
    "if predicted_class == 0:\n",
    "    predicted_label = \"real\"\n",
    "else:\n",
    "    predicted_label = \"fake\"\n",
    "\n",
    "    print(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ffcaf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/brian/Desktop/Camera AI/NasNetLarge ANN Model 1.ipynb Cell 9\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brian/Desktop/Camera%20AI/NasNetLarge%20ANN%20Model%201.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(img_array)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brian/Desktop/Camera%20AI/NasNetLarge%20ANN%20Model%201.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Check if the prediction score is greater than or equal to the threshold\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/brian/Desktop/Camera%20AI/NasNetLarge%20ANN%20Model%201.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mif\u001b[39;00m predictions \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m threshold:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brian/Desktop/Camera%20AI/NasNetLarge%20ANN%20Model%201.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     predicted_class \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfake\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brian/Desktop/Camera%20AI/NasNetLarge%20ANN%20Model%201.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "threshold = 0.99\n",
    "\n",
    "# Get model predictions\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Check if the prediction score is greater than or equal to the threshold\n",
    "if predictions >= threshold:\n",
    "    predicted_class = \"fake\"\n",
    "else:\n",
    "    predicted_class = \"real\"\n",
    "\n",
    "print(\"Predicted class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4671bf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predictions: [[0.40270525 0.59729475]]\n"
     ]
    }
   ],
   "source": [
    "#print(\"Model predictions:\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3afcc650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.build(input_shape=(None, 32, 32, 3))\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# history = model.fit(\n",
    "#   train_df,\n",
    "#   validation_data=test_df,\n",
    "#   epochs=5,\n",
    "#   verbose=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58df4b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0383c246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
